{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasQP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/18wh1a1240/QuickPeek/blob/main/kerasQP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRemL0euDqG4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5rpaG7C8CmF",
        "outputId": "9281a541-f36e-465f-d8c6-3d1e2b652aa7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "from tensorflow.keras.layers import Attention\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "0pfXcGJu9NAM",
        "outputId": "a9bf30c1-8de5-4ad3-8e22-f2d5a90f9020"
      },
      "source": [
        "reviews = pd.read_csv(\"/content/drive/MyDrive/DataSetsML/news_summary_more.csv\")\n",
        "print(reviews.shape)\n",
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98401, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-match winning streak</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customers save tax</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claims are not true: Sonam</td>\n",
              "      <td>Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             headlines                                                                                                                                                                                                     text\n",
              "0    upGrad learner switches to career in ML & Al with 90% salary hike  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program ...\n",
              "1         Delhi techie wins free food from Swiggy for one year on CRED  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coi...\n",
              "2     New Zealand end Rohit Sharma-led India's 12-match winning streak  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's capt...\n",
              "3             Aegon life iTerm insurance plan helps customers save tax  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, cust...\n",
              "4  Have known Hirani for yrs, what if MeToo claims are not true: Sonam  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"I..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNwCRxt-nBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab65a9b-ff63-4101-a1eb-638798222721"
      },
      "source": [
        "reviews.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headlines    0\n",
              "text         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiAc4dZs-87s"
      },
      "source": [
        "CURRENCIES = {\n",
        "    \"$\": \"USD\", \"zł\": \"PLN\", \"£\": \"GBP\", \"¥\": \"JPY\", \"฿\": \"THB\", \"₡\": \"CRC\", \"₦\": \"NGN\",\"₩\": \"KRW\",\n",
        "    \"₪\": \"ILS\", \"₫\": \"VND\", \"€\": \"EUR\", \"₱\": \"PHP\", \"₲\": \"PYG\", \"₴\": \"UAH\", \"₹\": \"INR\",}\n",
        "CURRENCY_REGEX = re.compile(\n",
        "    \"({})+\".format(\"|\".join(re.escape(c) for c in CURRENCIES.keys())))\n",
        "\n",
        "EMAIL_REGEX = re.compile(\n",
        "    r\"(?:^|(?<=[^\\w@.)]))([\\w+-](\\.(?!\\.))?)*?[\\w+-]@(?:\\w-?)*?\\w+(\\.([a-z]{2,})){1,3}(?:$|(?=\\b))\",\n",
        "    flags=re.IGNORECASE | re.UNICODE,)\n",
        "\n",
        "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
        "contractions =          {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\", \"i've\": \"i have\"}\n",
        "def clean_text(text, remove_stopwords = True):\n",
        "    \n",
        "    text = text.lower()\n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "        \n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = EMAIL_REGEX.sub(' ',text)\n",
        "    text = CURRENCY_REGEX.sub(' ',text)\n",
        "    text = ' '.join([contractions[t] if t in contractions else t for t in text.split(\" \")])    \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r\"'s\\b\",\"\", text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    \n",
        "    if remove_stopwords:\n",
        "        text = text.split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "        text = \" \".join(text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux-gOrJz_IoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1da4f92-a98f-4108-87ed-95f5fd990fb9"
      },
      "source": [
        "cleaned_headlines = []\n",
        "cleaned_text = []\n",
        "\n",
        "for headlines in reviews['headlines']:\n",
        "    cleaned_headlines.append(clean_text(headlines, remove_stopwords=False))\n",
        "print(\"Headlines are complete.\")\n",
        "\n",
        "for text in reviews['text']:\n",
        "    cleaned_text.append(clean_text(text))\n",
        "print(\"Texts are complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Headlines are complete.\n",
            "Texts are complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxGnVEwR_Lau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d136ea-89b9-4e38-f85f-fa40d3713f92"
      },
      "source": [
        "for i in range(4):\n",
        "    print(\"Review: \",i+1) # You can change it by \"Review\" to \"Headline\"\n",
        "    print(cleaned_headlines[i])\n",
        "    print('-'*80)\n",
        "    print(cleaned_text[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review:  1\n",
            "upgrad learner switches to career in ml   al with 90  salary hike\n",
            "--------------------------------------------------------------------------------\n",
            "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
            "\n",
            "Review:  2\n",
            "delhi techie wins free food from swiggy for one year on cred\n",
            "--------------------------------------------------------------------------------\n",
            "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit\n",
            "\n",
            "Review:  3\n",
            "new zealand end rohit sharma led india 12 match winning streak\n",
            "--------------------------------------------------------------------------------\n",
            "new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back march 2018 match witnessed india getting 92 seventh lowest total odi cricket history\n",
            "\n",
            "Review:  4\n",
            "aegon life iterm insurance plan helps customers save tax\n",
            "--------------------------------------------------------------------------------\n",
            "aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability accidental death benefit rider life cover age 80 years\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R67MPtGJ_OwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "51b79f12-a843-4f7e-ff43-d1c05c0d19d4"
      },
      "source": [
        "import matplotlib.pyplot as plt #pip install matplotlib\n",
        "\n",
        "text_word_count = []\n",
        "headlines_word_count = []\n",
        "\n",
        "for i in cleaned_text:\n",
        "    text_word_count.append(len(i.split()))\n",
        "for i in cleaned_headlines:\n",
        "    headlines_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text': text_word_count, 'headlines': headlines_word_count})\n",
        "length_df.hist(bins=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Bhkezm_SWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54bf1e2-4266-4d8c-b37d-b2840b06bd0d"
      },
      "source": [
        "count = 0\n",
        "for i in cleaned_text:\n",
        "    if(len(i.split())<=55):\n",
        "        count += 1\n",
        "print(count/len(cleaned_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9998882125181655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgACAMuS_VqN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "14d0a253-7e24-4df2-c843-243db2a26c2b"
      },
      "source": [
        "max_headlines_len=15\n",
        "max_text_len=55\n",
        "\n",
        "cleaned_text = np.array(cleaned_text)\n",
        "cleaned_headlines = np.array(cleaned_headlines)\n",
        "\n",
        "short_text=[]\n",
        "short_headlines=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    \n",
        "    if(len(cleaned_headlines[i].split())<=max_headlines_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_headlines.append(cleaned_headlines[i])\n",
        "\n",
        "df=pd.DataFrame({'text':short_text,'headlines':short_headlines})\n",
        "df['headlines'] = df['headlines'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['headlines']),test_size=0.1,random_state=0,shuffle=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>headlines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped tra...</td>\n",
              "      <td>sostok upgrad learner switches to career in ml   al with 90  salary hike eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rup...</td>\n",
              "      <td>sostok delhi techie wins free food from swiggy for one year on cred eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back m...</td>\n",
              "      <td>sostok new zealand end rohit sharma led india 12 match winning streak eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability ...</td>\n",
              "      <td>sostok aegon life iterm insurance plan helps customers save tax eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speaking sexual harassment allegations rajkumar hirani sonam kapoor said i've known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgmen...</td>\n",
              "      <td>sostok have known hirani for yrs  what if metoo claims are not true  sonam eostok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                      text                                                                          headlines\n",
              "0  saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped tra...    sostok upgrad learner switches to career in ml   al with 90  salary hike eostok\n",
              "1  kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rup...         sostok delhi techie wins free food from swiggy for one year on cred eostok\n",
              "2  new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back m...       sostok new zealand end rohit sharma led india 12 match winning streak eostok\n",
              "3  aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability ...             sostok aegon life iterm insurance plan helps customers save tax eostok\n",
              "4  speaking sexual harassment allegations rajkumar hirani sonam kapoor said i've known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgmen...  sostok have known hirani for yrs  what if metoo claims are not true  sonam eostok"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PySSvamF_Z96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7fb7bda-ba06-4837-c720-40f4bb5a3c80"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "thresh=4\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(x_voc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 61.83642437762905\n",
            "Total Coverage of rare words: 2.4873360532296487\n",
            "34386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OspLdXi_dhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57975f92-cabd-4d18-a49c-a35dd436002d"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "thresh=6\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_headlines_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_headlines_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "\n",
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 71.13547842913493\n",
            "Total Coverage of rare words: 4.878360245795404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88505, 88505)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kOGtR_P_iZO"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)\n",
        "\n",
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyFSLVv2_mSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640ea0f5-3ac4-446d-a8a5-5fecdbc6d27e"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 200\n",
        "embedding_dim=110\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 55, 110)      3782460     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 55, 200), (N 248800      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 55, 200), (N 320800      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 110)    1279960     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 55, 200), (N 320800      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 200),  248800      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 200),  80200       lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 400)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 11636)  4666036     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 10,947,856\n",
            "Trainable params: 10,947,856\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep4FU1Wp_rO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9951aef9-5924-437c-cd48-2c97264f5aa7"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "692/692 [==============================] - 552s 785ms/step - loss: 5.0173 - val_loss: 4.6274\n",
            "Epoch 2/10\n",
            "692/692 [==============================] - 543s 784ms/step - loss: 4.4750 - val_loss: 4.2775\n",
            "Epoch 3/10\n",
            "692/692 [==============================] - 540s 780ms/step - loss: 4.1965 - val_loss: 4.0668\n",
            "Epoch 4/10\n",
            "692/692 [==============================] - 544s 787ms/step - loss: 4.0030 - val_loss: 3.9314\n",
            "Epoch 5/10\n",
            "692/692 [==============================] - 542s 783ms/step - loss: 3.8594 - val_loss: 3.8232\n",
            "Epoch 6/10\n",
            "692/692 [==============================] - 543s 785ms/step - loss: 3.7407 - val_loss: 3.7350\n",
            "Epoch 7/10\n",
            "692/692 [==============================] - 543s 784ms/step - loss: 3.6459 - val_loss: 3.6682\n",
            "Epoch 8/10\n",
            "692/692 [==============================] - 542s 783ms/step - loss: 3.5621 - val_loss: 3.6070\n",
            "Epoch 9/10\n",
            "692/692 [==============================] - 539s 779ms/step - loss: 3.4933 - val_loss: 3.5643\n",
            "Epoch 10/10\n",
            "692/692 [==============================] - 532s 768ms/step - loss: 3.4352 - val_loss: 3.5248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "CFtSBm3q7NOX",
        "outputId": "d47b64e9-3f1e-407e-93a2-4d95db7ab62d"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHYgnexv_sae"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_headlines_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuPc0r7x_zM0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "4342bd90-9379-44d6-dd7f-c2f2aa231ccd"
      },
      "source": [
        "for i in range(0,10):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1618e95abb6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq2text' is not defined"
          ]
        }
      ]
    }
  ]
}