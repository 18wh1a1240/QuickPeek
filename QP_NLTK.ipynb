{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QP_NLTK.ipynb",
      "provenance": [],
      "mount_file_id": "1XCJDqNNGlbLStWI3cJ7FEm1FF0s1F056",
      "authorship_tag": "ABX9TyNzTu2239i+B3/BaWr6TM2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/18wh1a1240/QuickPeek/blob/main/QP_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur7hdsCGExdK",
        "outputId": "15f51080-7ab6-4d89-95ed-ca6b7ed009a9"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from pickle import dump, load\n",
        "reviews = pd.read_csv('/content/drive/MyDrive/DataSetsML/news_summary_more.csv')\n",
        "print(reviews.shape)\n",
        "print(reviews.head())\n",
        "print(reviews.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(98401, 2)\n",
            "                                           headlines                                               text\n",
            "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
            "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
            "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
            "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
            "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio...\n",
            "headlines    0\n",
            "text         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_azMu6NFMFH",
        "outputId": "70bf9d1c-259a-4dd8-dc50-1ec8b64d016b"
      },
      "source": [
        "reviews = reviews.reset_index(drop=True)\n",
        "print(reviews.shape)\n",
        "print(reviews.head())\n",
        "for i in range(5):\n",
        "    print(\"Review #\",i+1)\n",
        "    print(reviews.headlines[i])\n",
        "    print(reviews.text[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98401, 2)\n",
            "                                           headlines                                               text\n",
            "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
            "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
            "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
            "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
            "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio...\n",
            "Review # 1\n",
            "upGrad learner switches to career in ML & Al with 90% salary hike\n",
            "Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
            "\n",
            "Review # 2\n",
            "Delhi techie wins free food from Swiggy for one year on CRED\n",
            "Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
            "\n",
            "Review # 3\n",
            "New Zealand end Rohit Sharma-led India's 12-match winning streak\n",
            "New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
            "\n",
            "Review # 4\n",
            "Aegon life iTerm insurance plan helps customers save tax\n",
            "With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
            "\n",
            "Review # 5\n",
            "Have known Hirani for yrs, what if MeToo claims are not true: Sonam\n",
            "Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman. But in this case, we need to reserve our judgment,\" she added. Hirani has been accused by an assistant who worked in 'Sanju'.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocFPgAb5FR2r"
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how does\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSC8bFBnFYjD"
      },
      "source": [
        "def clean_text(text, remove_stopwords = True):\n",
        "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
        "    \n",
        "    text = text.lower()\n",
        "    \n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "    \n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    \n",
        "    if remove_stopwords:\n",
        "        text = text.split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "        text = \" \".join(text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjjN8basFcNn",
        "outputId": "6c35c8f7-e8c3-4e28-8f6f-2af4bda97dea"
      },
      "source": [
        "clean_summaries = []\n",
        "for summary in reviews.headlines:\n",
        "    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
        "print(\"Summaries are complete.\")\n",
        "\n",
        "clean_texts = []\n",
        "for text in reviews.text:\n",
        "    clean_texts.append(clean_text(text))\n",
        "print(\"Texts are complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summaries are complete.\n",
            "Texts are complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iUe89k6Gemw",
        "outputId": "9432cdb2-9e94-4c45-c34f-926d6d4520fe"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"Clean Review #\",i+1)\n",
        "    print(clean_summaries[i])\n",
        "    print(clean_texts[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clean Review # 1\n",
            "upgrad learner switches to career in ml   al with 90  salary hike\n",
            "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
            "\n",
            "Clean Review # 2\n",
            "delhi techie wins free food from swiggy for one year on cred\n",
            "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit\n",
            "\n",
            "Clean Review # 3\n",
            "new zealand end rohit sharma led india s 12 match winning streak\n",
            "new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back march 2018 match witnessed india getting 92 seventh lowest total odi cricket history\n",
            "\n",
            "Clean Review # 4\n",
            "aegon life iterm insurance plan helps customers save tax\n",
            "aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability accidental death benefit rider life cover age 80 years\n",
            "\n",
            "Clean Review # 5\n",
            "have known hirani for yrs  what if metoo claims are not true  sonam\n",
            "speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4fEnwWOGufM"
      },
      "source": [
        "stories = list()\n",
        "for i, text in enumerate(clean_texts):\n",
        "    stories.append({'story': text, 'highlights': clean_summaries[i]})\n",
        "\n",
        "dump(stories, open('review_dataset.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRgOOkhKGyg1",
        "outputId": "246ec87c-2b15-467f-b7da-ae74351d1006"
      },
      "source": [
        "stories = load(open('review_dataset.pkl', 'rb'))\n",
        "print('Loaded Stories %d' % len(stories))\n",
        "print(type(stories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Stories 98401\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5yenWpqG4Vt"
      },
      "source": [
        "def count_words(count_dict, text):\n",
        "    '''Count the number of occurrences of each word in a set of text'''\n",
        "    for sentence in text:\n",
        "        for word in sentence.split():\n",
        "            if word not in count_dict:\n",
        "                count_dict[word] = 1\n",
        "            else:\n",
        "                count_dict[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbQU8K62G6EQ",
        "outputId": "a5b19b18-9657-454f-92c9-ea3be08b0f99"
      },
      "source": [
        "word_counts = {}\n",
        "\n",
        "count_words(word_counts, clean_summaries)\n",
        "count_words(word_counts, clean_texts)\n",
        "            \n",
        "print(\"Size of Vocabulary:\", len(word_counts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Vocabulary: 84874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWaWUK9DG9rj",
        "outputId": "c3263a8a-956d-43f6-9173-1505d8107862"
      },
      "source": [
        "embeddings_index = []\n",
        "\n",
        "missing_words = 0\n",
        "threshold = 20\n",
        "\n",
        "for word, count in word_counts.items():\n",
        "    if count > threshold:\n",
        "        if word not in embeddings_index:\n",
        "            missing_words += 1\n",
        "            \n",
        "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
        "            \n",
        "print(\"Number of words missing from CN:\", missing_words)\n",
        "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words missing from CN: 16249\n",
            "Percent of words that are missing from vocabulary: 19.139999999999997%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-JemqEQHBZ3",
        "outputId": "6ffedfd4-4e95-4900-ae4d-9fa0edd6a8a0"
      },
      "source": [
        "# Dictionary to convert integers to words\n",
        "vocab_to_int = {} \n",
        "\n",
        "value = 0\n",
        "for word, count in word_counts.items():\n",
        "    if count >= threshold or word in embeddings_index:\n",
        "        vocab_to_int[word] = value\n",
        "        value += 1\n",
        "\n",
        "# Special tokens that will be added to our vocab\n",
        "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
        "\n",
        "# Add codes to vocab\n",
        "for code in codes:\n",
        "    vocab_to_int[code] = len(vocab_to_int)\n",
        "\n",
        "\n",
        "int_to_vocab = {}\n",
        "for word, value in vocab_to_int.items():\n",
        "    int_to_vocab[value] = word\n",
        "\n",
        "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
        "\n",
        "print(\"Total number of unique words:\", len(word_counts))\n",
        "print(\"Number of words we will use:\", len(vocab_to_int))\n",
        "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique words: 84874\n",
            "Number of words we will use: 16686\n",
            "Percent of words we will use: 19.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFLJqSi2HJAE",
        "outputId": "ee843613-61fd-41c3-87a3-ef569ff759a9"
      },
      "source": [
        "#Embedding\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "embedding_dim = 300\n",
        "nb_words = len(vocab_to_int)\n",
        "\n",
        "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
        "for word, i in vocab_to_int.items():\n",
        "    if word in embeddings_index:\n",
        "        word_embedding_matrix[i] = embeddings_index[word]\n",
        "    else:\n",
        "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
        "        word_embedding_matrix[i] = new_embedding\n",
        "\n",
        "print(len(word_embedding_matrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hafxXW7eHMly"
      },
      "source": [
        "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
        "    '''Convert words in text to an integer.\n",
        "       If word is not in vocab_to_int, use UNK's integer.\n",
        "       Total the number of words and UNKs.\n",
        "       Add EOS token to the end of texts'''\n",
        "    ints = []\n",
        "    for sentence in text:\n",
        "        sentence_ints = []\n",
        "        for word in sentence.split():\n",
        "            word_count += 1\n",
        "            if word in vocab_to_int:\n",
        "                sentence_ints.append(vocab_to_int[word])\n",
        "            else:\n",
        "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
        "                unk_count += 1\n",
        "        if eos:\n",
        "            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
        "        ints.append(sentence_ints)\n",
        "    return ints, word_count, unk_count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT4I9PFaHOVl",
        "outputId": "56b89877-6b27-4b5c-b77d-97a9ed71df71"
      },
      "source": [
        "word_count = 0\n",
        "unk_count = 0\n",
        "\n",
        "int_summaries, word_count, unk_count = convert_to_ints(clean_summaries, word_count, unk_count)\n",
        "int_texts, word_count, unk_count = convert_to_ints(clean_texts, word_count, unk_count, eos=True)\n",
        "\n",
        "unk_percent = round(unk_count/word_count,4)*100\n",
        "\n",
        "print(\"Total number of words in headlines:\", word_count)\n",
        "print(\"Total number of UNKs in headlines:\", unk_count)\n",
        "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words in headlines: 4638385\n",
            "Total number of UNKs in headlines: 249420\n",
            "Percent of words that are UNK: 5.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-vBPZWCHVw1"
      },
      "source": [
        "def create_lengths(text):\n",
        "    '''Create a data frame of the sentence lengths from a text'''\n",
        "    lengths = []\n",
        "    for sentence in text:\n",
        "        lengths.append(len(sentence))\n",
        "    return pd.DataFrame(lengths, columns=['counts'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPnaXdXaHZMX",
        "outputId": "46b52d59-3f8a-4159-d8cd-b3ada96c6af5"
      },
      "source": [
        "lengths_summaries = create_lengths(int_summaries)\n",
        "lengths_texts = create_lengths(int_texts)\n",
        "\n",
        "print(\"Summaries:\")\n",
        "print(lengths_summaries.describe())\n",
        "print()\n",
        "print(\"Texts:\")\n",
        "print(lengths_texts.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summaries:\n",
            "             counts\n",
            "count  98401.000000\n",
            "mean      10.050457\n",
            "std        1.565373\n",
            "min        1.000000\n",
            "25%        9.000000\n",
            "50%       10.000000\n",
            "75%       11.000000\n",
            "max       18.000000\n",
            "\n",
            "Texts:\n",
            "             counts\n",
            "count  98401.000000\n",
            "mean      38.087123\n",
            "std        4.294684\n",
            "min        2.000000\n",
            "25%       35.000000\n",
            "50%       38.000000\n",
            "75%       41.000000\n",
            "max       61.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44n70JIvHd8y",
        "outputId": "d6f89914-d044-46f3-c00d-403043fb1015"
      },
      "source": [
        "print(np.percentile(lengths_texts.counts, 90))\n",
        "print(np.percentile(lengths_texts.counts, 95))\n",
        "print(np.percentile(lengths_texts.counts, 99))\n",
        "\n",
        "print(np.percentile(lengths_summaries.counts, 90))\n",
        "print(np.percentile(lengths_summaries.counts, 95))\n",
        "print(np.percentile(lengths_summaries.counts, 99))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44.0\n",
            "45.0\n",
            "49.0\n",
            "12.0\n",
            "13.0\n",
            "14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nquA29enHlNq"
      },
      "source": [
        "def unk_counter(sentence):\n",
        "    '''Counts the number of time UNK appears in a sentence.'''\n",
        "    unk_count = 0\n",
        "    for word in sentence:\n",
        "        if word == vocab_to_int[\"<UNK>\"]:\n",
        "            unk_count += 1\n",
        "    return unk_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCzoN2OIHnAa",
        "outputId": "11fe67e7-496e-4a11-da11-eba6bc13c590"
      },
      "source": [
        "sorted_summaries = []\n",
        "sorted_texts = []\n",
        "max_text_length = 84\n",
        "max_summary_length = 13\n",
        "min_length = 2\n",
        "unk_text_limit = 100 \n",
        "unk_summary_limit = 100 \n",
        "\n",
        "for length in range(min(lengths_texts.counts), max_text_length): \n",
        "    for count, words in enumerate(int_summaries):\n",
        "        if (len(int_summaries[count]) >= min_length and\n",
        "            len(int_summaries[count]) <= max_summary_length and\n",
        "            len(int_texts[count]) >= min_length and\n",
        "            unk_counter(int_summaries[count]) <= unk_summary_limit and\n",
        "            unk_counter(int_texts[count]) <= unk_text_limit and\n",
        "            length == len(int_texts[count])\n",
        "           ):\n",
        "            sorted_summaries.append(int_summaries[count])\n",
        "            sorted_texts.append(int_texts[count])\n",
        "        \n",
        "# Compare lengths to ensure they match\n",
        "print(len(sorted_summaries))\n",
        "print(len(sorted_texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96781\n",
            "96781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf_GICYUH8s2",
        "outputId": "7b32e9d4-3ea1-4365-ddcf-67e5b4e55919"
      },
      "source": [
        "for i in range(20):\n",
        "    print(\"Review #\", i + 1)\n",
        "    print(clean_texts[i])\n",
        "    print(\"Summary #\", clean_summaries[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review # 1\n",
            "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
            "Summary # upgrad learner switches to career in ml   al with 90  salary hike\n",
            "\n",
            "Review # 2\n",
            "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit\n",
            "Summary # delhi techie wins free food from swiggy for one year on cred\n",
            "\n",
            "Review # 3\n",
            "new zealand defeated india 8 wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy 12 consecutive victories dating back march 2018 match witnessed india getting 92 seventh lowest total odi cricket history\n",
            "Summary # new zealand end rohit sharma led india s 12 match winning streak\n",
            "\n",
            "Review # 4\n",
            "aegon life iterm insurance plan customers enjoy tax benefits premiums paid save â¹46 800^ taxes plan provides life cover age 100 years also customers options insure critical illnesses disability accidental death benefit rider life cover age 80 years\n",
            "Summary # aegon life iterm insurance plan helps customers save tax\n",
            "\n",
            "Review # 5\n",
            "speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju\n",
            "Summary # have known hirani for yrs  what if metoo claims are not true  sonam\n",
            "\n",
            "Review # 6\n",
            "pakistani singer rahat fateh ali khan denied receiving notice enforcement directorate allegedly smuggling foreign currency india would better authorities would served notice first publicised reads press release issued behalf rahat statement called allegation bizarre\n",
            "Summary # rahat fateh ali khan denies getting notice for smuggling currency\n",
            "\n",
            "Review # 7\n",
            "india recorded lowest odi total new zealand getting 92 runs 30 5 overs fourth odi hamilton thursday seven india batsmen dismissed single digit scores number ten batsman yuzvendra chahal top scored 18 37 india previous lowest odi total new zealand 108\n",
            "Summary # india get all out for 92  their lowest odi total in new zealand\n",
            "\n",
            "Review # 8\n",
            "weeks ex cbi director alok verma told department personnel training consider retired home ministry asked join work last day fixed tenure director thursday ministry directed immediately join dg fire services post transferred removal cbi chief\n",
            "Summary # govt directs alok verma to join work 1 day before his retirement\n",
            "\n",
            "Review # 9\n",
            "andhra pradesh cm n chandrababu naidu said met us president bill clinton addressed mr clinton sir pm narendra modi junior politics addressed sir 10 times satisfy ego hope justice state added\n",
            "Summary # called pm modi  sir  10 times to satisfy his ego  andhra cm\n",
            "\n",
            "Review # 10\n",
            "congress candidate shafia zubair ramgarh assembly seat rajasthan defeating bjp sukhwant singh margin 12 228 votes bypoll victory congress taken total 100 seats 200 member assembly election ramgarh seat delayed due death sitting mla bsp candidate laxman singh\n",
            "Summary # cong wins ramgarh bypoll in rajasthan  takes total to 100 seats\n",
            "\n",
            "Review # 11\n",
            "two minor cousins uttar pradesh gorakhpur allegedly repeatedly burnt tongs forced eat human excreta family friends two boys school cousins revealed ordeal police child welfare committee brought back gorakhpur nepal fled escape torture\n",
            "Summary # up cousins fed human excreta for friendship with boys\n",
            "\n",
            "Review # 12\n",
            "isha ghosh 81 year old member bharat scouts guides bsg imparting physical mental training schoolchildren jharkhand several decades chaibasa based ghosh reportedly walks seven kilometres daily spends eight hours conducting physical training apart climbing yoga sessions says one something society till one last breath\n",
            "Summary # 81 yr old woman conducts physical training in j khand schools\n",
            "\n",
            "Review # 13\n",
            "urging saints seers kumbh mela quit smoking yoga guru ramdev said follow ram krishna never smoked life making take pledge quit tobacco collected chillum clay pipe several sadhus said deposit chillums display museum build\n",
            "Summary # ram  krishna did not smoke  why should we  ramdev to sadhus at kumbh\n",
            "\n",
            "Review # 14\n",
            "former stripper regional sales director pharmaceutical company sunrise lee gave doctor lap dance nightclub persuade prescribe addictive fentanyl spray 2012 company sales representative told us court said saw lee sitting doctor lap kind bouncing around lee accused bribing doctors\n",
            "Summary # pharma exec gave doctor a lap dance to sell medicine in us  witness\n",
            "\n",
            "Review # 15\n",
            "reliance industries chairman mukesh ambani daughter isha ambani got married last month said cried bidaai felt peer pressure everyone crying especially parents emotional everyone around would cry time added emotional affair everyone family said isha\n",
            "Summary # i only cried at my  bidaai  as i felt peer pressure  isha ambani\n",
            "\n",
            "Review # 16\n",
            "louis vuitton owner lvmh makes high end beverages like moã«t chandon champagne hennessy cognac said stockpiling four months worth wine spirits uk preparation brexit ready worst case scenario difficulties deliveries french luxury giant said uk scheduled leave eu march 29\n",
            "Summary # louis vuitton owner to stockpile 4 months of wine  spirits in uk\n",
            "\n",
            "Review # 17\n",
            "filmmaker karan johar actress tabu turned showstoppers gaurav gupta opening night lakmã© fashion week summer resort 2019 johar wore red sequinned jacket black pants tabu walked ramp grey embellished gown fashion show began january 29 continue till february 3\n",
            "Summary # karan johar  tabu turn showstoppers on opening night of lfw\n",
            "\n",
            "Review # 18\n",
            "jibe congress president rahul gandhi pm narendra modi wednesday said bail go jail pm modi added bail associates facing charges know convicted one day pm claimed waged war corruption common household\n",
            "Summary # those on bail will go to jail  pm modi takes jibe at rahul\n",
            "\n",
            "Review # 19\n",
            "days threatened step post congress mlas continue crossing line karnataka chief minister hd kumaraswamy accused taking potshots asked many days tolerate stuff kumaraswamy made statements congress mla demanded siddaramaiah made cm said power ephemeral\n",
            "Summary # how long can i tolerate congress leaders  potshots  k taka cm\n",
            "\n",
            "Review # 20\n",
            "union minister dharmendra pradhan wednesday claimed illegal mining mafia odisha operates control cm naveen patnaik state congress chief niranjan patnaik added time come people odisha put full stop activities time come us ask explanation corrupt government\n",
            "Summary # odisha cm patnaik controls mining mafia  union minister\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}